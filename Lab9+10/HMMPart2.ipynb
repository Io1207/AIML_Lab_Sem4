{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS tagging using HMMs - Lab 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/cs240lab/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /home/cs240lab/nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#All imports\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "# Download the Brown corpus and the universal tagset\n",
    "nltk.download(\"brown\")\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the tagged sentences from the Brown corpus\n",
    "tagged_sentences = brown.tagged_sents(tagset=\"universal\")\n",
    "tagged_sentences = list(tagged_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('It', 'PRON'),\n",
       " ('recommended', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('Fulton', 'NOUN'),\n",
       " ('legislators', 'NOUN'),\n",
       " ('act', 'VERB'),\n",
       " ('``', '.'),\n",
       " ('to', 'PRT'),\n",
       " ('have', 'VERB'),\n",
       " ('these', 'DET'),\n",
       " ('laws', 'NOUN'),\n",
       " ('studied', 'VERB'),\n",
       " ('and', 'CONJ'),\n",
       " ('revised', 'VERB'),\n",
       " ('to', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('end', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('modernizing', 'VERB'),\n",
       " ('and', 'CONJ'),\n",
       " ('improving', 'VERB'),\n",
       " ('them', 'PRON'),\n",
       " (\"''\", '.'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sentences[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('it', 'PRON'),\n",
       " ('recommended', 'VERB'),\n",
       " ('that', 'ADP'),\n",
       " ('fulton', 'NOUN'),\n",
       " ('legislators', 'NOUN'),\n",
       " ('act', 'VERB'),\n",
       " ('``', '.'),\n",
       " ('to', 'PRT'),\n",
       " ('have', 'VERB'),\n",
       " ('these', 'DET'),\n",
       " ('laws', 'NOUN'),\n",
       " ('studied', 'VERB'),\n",
       " ('and', 'CONJ'),\n",
       " ('revised', 'VERB'),\n",
       " ('to', 'ADP'),\n",
       " ('the', 'DET'),\n",
       " ('end', 'NOUN'),\n",
       " ('of', 'ADP'),\n",
       " ('modernizing', 'VERB'),\n",
       " ('and', 'CONJ'),\n",
       " ('improving', 'VERB'),\n",
       " ('them', 'PRON'),\n",
       " (\"''\", '.'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in tagged_sentences:\n",
    "    for j in range(len(i)):\n",
    "        placeholder=(i[j][0].lower(),i[j][1])\n",
    "        i[j]=placeholder\n",
    "\n",
    "tagged_sentences[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Mapping from States and Observation Traces to numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 49815\n"
     ]
    }
   ],
   "source": [
    "states=[]\n",
    "observations=[]\n",
    "\n",
    "for j in tagged_sentences:\n",
    "    for i in j:\n",
    "        if not(i[-1] in states):\n",
    "            states.append(i[-1])\n",
    "        if not(i[0] in observations):\n",
    "            observations.append(i[0])\n",
    "\n",
    "print(len(states),len(observations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 'BOS', '1': 'DET', '2': 'NOUN', '3': 'ADJ', '4': 'VERB', '5': 'ADP', '6': '.', '7': 'ADV', '8': 'CONJ', '9': 'PRT', '10': 'PRON', '11': 'NUM', '12': 'X', '13': 'EOS'}\n"
     ]
    }
   ],
   "source": [
    "#mapping from states to numbers (indices in matrix)\n",
    "stateMap={'BOS':0}\n",
    "j=1\n",
    "for i in states:\n",
    "    stateMap[i]=j\n",
    "    j=j+1\n",
    "stateMap['EOS']=j\n",
    "# print(stateMap)\n",
    "\n",
    "numToStates={}\n",
    "j=0\n",
    "for i in stateMap:\n",
    "    numToStates[str(j)]=i\n",
    "    j=j+1\n",
    "\n",
    "print(numToStates)\n",
    "\n",
    "#mapping from observation traces to numbers\n",
    "obsMap={'eps':0}\n",
    "k=1\n",
    "for i in observations:\n",
    "    obsMap[i]=k\n",
    "    k=k+1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using KFold from sklearn to create folds\n",
    "kf=KFold(n_splits=5,shuffle=False)\n",
    "\n",
    "OneSmoothedTrans=[]\n",
    "OneSmoothedEmm=[]\n",
    "\n",
    "for trainIndices,testIndices in kf.split(tagged_sentences):\n",
    "\n",
    "    training=[tagged_sentences[i] for i in trainIndices]\n",
    "    test=[tagged_sentences[i] for i in testIndices]\n",
    "\n",
    "    obsStateMatrix=np.zeros((len(states)+2,len(observations)+1))+1\n",
    "    stateMatrix=np.zeros((len(states)+2,len(states)+2))+1\n",
    "    y=len(tagged_sentences)\n",
    "    for i in range(y):\n",
    "        z=len(tagged_sentences[i])\n",
    "        for j in range(z):\n",
    "            if j==0:\n",
    "                stateMatrix[stateMap['BOS']][stateMap[tagged_sentences[i][j][-1]]]=stateMatrix[stateMap['BOS']][stateMap[tagged_sentences[i][j][-1]]]+1\n",
    "                stateMatrix[stateMap['BOS']][obsMap['eps']]=stateMatrix[stateMap['BOS']][obsMap['eps']]+1\n",
    "            if j==z-1:\n",
    "                stateMatrix[stateMap['EOS']][stateMap['BOS']]=stateMatrix[stateMap['EOS']][stateMap['BOS']]+1\n",
    "                stateMatrix[stateMap['EOS']][obsMap['eps']]=stateMatrix[stateMap['EOS']][obsMap['eps']]+1\n",
    "            if j<z-1:\n",
    "                nextState=tagged_sentences[i][j+1][-1]\n",
    "                currObs=tagged_sentences[i][j][0]\n",
    "                currState=tagged_sentences[i][j][-1]\n",
    "\n",
    "                stateMatrix[stateMap[currState]][stateMap[nextState]]=stateMatrix[stateMap[currState]][stateMap[nextState]]+1\n",
    "                obsStateMatrix[stateMap[currState]][obsMap[currObs]]=obsStateMatrix[stateMap[currState]][obsMap[currObs]]+1\n",
    "                \n",
    "    stateMatrix=stateMatrix/(stateMatrix.sum(axis=1,keepdims=True))\n",
    "    obsStateMatrix=obsStateMatrix/(obsStateMatrix.sum(axis=1,keepdims=True))\n",
    "    OneSmoothedEmm.append(obsStateMatrix)\n",
    "    OneSmoothedTrans.append(stateMatrix)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Split 1</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Emission Matrix\n",
      "(14, 49816)\n"
     ]
    }
   ],
   "source": [
    "# print(\"transition matrix\")\n",
    "# print(OneSmoothedTrans[0])\n",
    "print()\n",
    "print(\"Emission Matrix\")\n",
    "print(OneSmoothedEmm[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PRON', 'VERB', 'ADP', 'NOUN', 'NOUN', 'NOUN', '.', 'PRT', 'VERB', 'DET', 'NOUN', 'VERB', 'CONJ', 'VERB', 'ADP', 'DET', 'NOUN', 'ADP', 'NOUN', 'CONJ', 'VERB', 'PRON', '.', 'CONJ']\n"
     ]
    }
   ],
   "source": [
    "# def viterbi(obs, states, start_p, trans_p, emit_p):\n",
    "#     V = [{}]\n",
    "#     path = {}\n",
    "#     for y in states:\n",
    "#         V[0][y] = start_p[y] * emit_p[y][obs[0]]\n",
    "#         path[y] = [y]\n",
    "#     for t in range(1, len(obs)):\n",
    "#         V.append({})\n",
    "#         newpath = {}\n",
    "#         for y in states:\n",
    "#             (prob, state) = max([(V[t-1][y0] * trans_p[y0][y] * emit_p[y][obs[t]], y0) for y0 in states])\n",
    "#             V[t][y] = prob\n",
    "#             newpath[y] = path[state] + [y]\n",
    "#         path = newpath\n",
    "#     (prob, state) = max([(V[-1][y], y) for y in states])\n",
    "#     return (prob, path[state])\n",
    "\n",
    "\n",
    "def viterbiCS217(observe:str, trans_p:np.array, emit_p:np.array):\n",
    "    # return\n",
    "    observe.insert(0,'eps')\n",
    "    N=len(stateMap)\n",
    "    t=len(observe)\n",
    "    seqScore=np.zeros((N,t))\n",
    "    seqScore[0][obsMap['eps']]=1 #start with BOS and epsilon char\n",
    "    for i in range(1,N):\n",
    "        seqScore[i][obsMap['eps']]=0\n",
    "    backPtr=np.zeros((N,t))\n",
    "    backPtr.astype(int)\n",
    "    backPtr[0][0]=None\n",
    "    # count=0\n",
    "\n",
    "    for t_iter in range(1,t):\n",
    "        for i in range(1,N):\n",
    "            seqScore[i][t_iter],backPtr[i][t_iter]=max([(seqScore[j][t_iter-1] * trans_p[j][i] * emit_p[i][obsMap[observe[t_iter]]], j) for j in range(0,N)])\n",
    "            \n",
    "    s,currLast=max([(seqScore[j][t-1],j) for j in range(0,N)])\n",
    "    position=t\n",
    "    path=[]\n",
    "    while position!=0:\n",
    "        path.append(currLast)\n",
    "        currLast=backPtr[int(currLast)][position-1]\n",
    "        position=position-1\n",
    "\n",
    "    path.reverse()\n",
    "    path.append(stateMap['EOS'])\n",
    "\n",
    "    return path\n",
    "\n",
    "def answer(sentence,transiton,emmission):\n",
    "    path=viterbiCS217(sentence,transiton,emmission)\n",
    "    for i in range(len(path)):\n",
    "         path[i]=int(path[i])\n",
    "    # path=path.astype(int)\n",
    "    posTagging=[]\n",
    "    for i in range(1,len(sentence)):\n",
    "        posTagging.append(numToStates[str(int(path[i]))])\n",
    "    \n",
    "    return posTagging\n",
    "\n",
    "\n",
    "sentence=[]\n",
    "for i in tagged_sentences[5]:\n",
    "        sentence.append(i[0])\n",
    "print(answer(sentence,OneSmoothedTrans[0],OneSmoothedEmm[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsStateMatrix=np.zeros((len(states)+2,len(observations)+1))+1\n",
    "stateMatrix=np.zeros((len(states)+2,len(states)+2))+1\n",
    "y=len(tagged_sentences)\n",
    "for i in range(y):\n",
    "    z=len(tagged_sentences[i])\n",
    "    for j in range(z):\n",
    "        if j==0:\n",
    "            stateMatrix[stateMap['BOS']][stateMap[tagged_sentences[i][j][-1]]]=stateMatrix[stateMap['BOS']][stateMap[tagged_sentences[i][j][-1]]]+1\n",
    "            stateMatrix[stateMap['BOS']][obsMap['eps']]=stateMatrix[stateMap['BOS']][obsMap['eps']]+1\n",
    "        if j==z-1:\n",
    "            stateMatrix[stateMap['EOS']][stateMap['BOS']]=stateMatrix[stateMap['EOS']][stateMap['BOS']]+1\n",
    "            stateMatrix[stateMap['EOS']][obsMap['eps']]=stateMatrix[stateMap['EOS']][obsMap['eps']]+1\n",
    "        if j<z-1:\n",
    "            nextState=tagged_sentences[i][j+1][-1]\n",
    "            currObs=tagged_sentences[i][j][0]\n",
    "            currState=tagged_sentences[i][j][-1]\n",
    "            stateMatrix[stateMap[currState]][stateMap[nextState]]=stateMatrix[stateMap[currState]][stateMap[nextState]]+1\n",
    "            obsStateMatrix[stateMap[currState]][obsMap[currObs]]=obsStateMatrix[stateMap[currState]][obsMap[currObs]]+1                \n",
    "stateMatrix=stateMatrix/(stateMatrix.sum(axis=1,keepdims=True))\n",
    "obsStateMatrix=obsStateMatrix/(obsStateMatrix.sum(axis=1,keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "1\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "2\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "3\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "4\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n"
     ]
    }
   ],
   "source": [
    "kf=KFold(n_splits=5,shuffle=False)\n",
    "\n",
    "step=0\n",
    "answers=[]\n",
    "labels=[]\n",
    "\n",
    "for trainIndices,testIndices in kf.split(tagged_sentences):\n",
    "    print(step)\n",
    "    training=[tagged_sentences[i] for i in trainIndices]\n",
    "    test=[tagged_sentences[i] for i in testIndices]\n",
    "    # print(testIndices)\n",
    "    sentences=[]\n",
    "    for i in range(11468):\n",
    "        # print(testIndices[i],end=\"\")\n",
    "        if i%1000==0:\n",
    "             print(i)\n",
    "        testSentence=[]\n",
    "        for j in test[i]:\n",
    "                testSentence.append(j[0])\n",
    "                labels.append(j[1])\n",
    "        sentences.append(testSentence)\n",
    "        \n",
    "    #testing\n",
    "    for sent in sentences:\n",
    "        result=answer(sent,OneSmoothedTrans[step],OneSmoothedEmm[step])\n",
    "        answers=answers+result\n",
    "\n",
    "    step=step+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           .       0.96      0.88      0.92    147565\\n         ADJ       0.88      0.91      0.90     83721\\n         ADP       0.92      0.97      0.95    144766\\n         ADV       0.83      0.88      0.85     56239\\n        CONJ       0.90      0.99      0.94     38151\\n         DET       0.92      0.99      0.95    137019\\n         EOS       0.00      0.00      0.00         0\\n        NOUN       0.95      0.92      0.94    275558\\n         NUM       0.98      0.83      0.90     14874\\n        PRON       0.92      0.96      0.94     49334\\n         PRT       0.91      0.86      0.88     29829\\n        VERB       0.96      0.93      0.94    182750\\n           X       0.72      0.44      0.54      1386\\n\\n    accuracy                           0.93   1161192\\n   macro avg       0.83      0.81      0.82   1161192\\nweighted avg       0.93      0.93      0.93   1161192\\n'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(labels,answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        precision    recall  f1-score   support\\n\\n           \n",
    ".       0.96      0.88      0.92    147565\\n         \n",
    "ADJ       0.88      0.91      0.90     83721\\n         \n",
    "ADP       0.92      0.97      0.95    144766\\n         \n",
    "ADV       0.83      0.88      0.85     56239\\n        \n",
    "CONJ       0.90      0.99      0.94     38151\\n         \n",
    "DET       0.92      0.99      0.95    137019\\n         \n",
    "EOS       0.00      0.00      0.00         0\\n        \n",
    "NOUN       0.95      0.92      0.94    275558\\n         \n",
    "NUM       0.98      0.83      0.90     14874\\n        \n",
    "PRON       0.92      0.96      0.94     49334\\n         \n",
    "PRT       0.91      0.86      0.88     29829\\n        \n",
    "VERB       0.96      0.93      0.94    182750\\n           \n",
    "X       0.72      0.44      0.54      1386\\n\\n    \n",
    "accuracy                           0.93   1161192\\n   \n",
    "macro avg       0.83      0.81      0.82   1161192\\n\n",
    "weighted avg       0.93      0.93      0.93   1161192\\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
